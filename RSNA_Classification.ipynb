{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 39272,
          "databundleVersionId": 4629629,
          "sourceType": "competition"
        },
        {
          "sourceId": 4619805,
          "sourceType": "datasetVersion",
          "datasetId": 2688675
        }
      ],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "RSNA_Classification",
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ba6e00aebe65498997d97a206acaf0a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83f52b6dfae24c218359dc486e30d3b1"
            ],
            "layout": "IPY_MODEL_3a93ef68b76d47ffa8af108909cf24db"
          }
        },
        "b805d3f222374d2db10d97f2cd50ec95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09c470fa6dd24c1b8b5031e86853e05f",
            "placeholder": "​",
            "style": "IPY_MODEL_c5acca357cc14060b6e4b2fb0a5545ec",
            "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
          }
        },
        "b0a0e5329299463f8221bc0346d2de41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Username:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_458af312174949a5b0981db395fc424b",
            "placeholder": "​",
            "style": "IPY_MODEL_8b579461d248418c8028113f54522cdc",
            "value": "raksa07"
          }
        },
        "a734cea2dd2742c3946e5c5723c5121d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_16552956cc3e44dd864a111c55136f57",
            "placeholder": "​",
            "style": "IPY_MODEL_3371c4865e5241cea66d5f0a7bb56951",
            "value": ""
          }
        },
        "c295fa9a5fe241ce93e88c7b29b9dd4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_b73e41c87fb64aa9b1bc3d8bd0dd1893",
            "style": "IPY_MODEL_d757aa3788b5443d863eb9fca2bfdb1f",
            "tooltip": ""
          }
        },
        "50418299f32b4803a7ff5a34e73f1bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6b7e592da484e27bf02d11f50f6d74d",
            "placeholder": "​",
            "style": "IPY_MODEL_e4172a1b303748c985990a5174755159",
            "value": "\n<b>Thank You</b></center>"
          }
        },
        "3a93ef68b76d47ffa8af108909cf24db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "09c470fa6dd24c1b8b5031e86853e05f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5acca357cc14060b6e4b2fb0a5545ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "458af312174949a5b0981db395fc424b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b579461d248418c8028113f54522cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16552956cc3e44dd864a111c55136f57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3371c4865e5241cea66d5f0a7bb56951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b73e41c87fb64aa9b1bc3d8bd0dd1893": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d757aa3788b5443d863eb9fca2bfdb1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "f6b7e592da484e27bf02d11f50f6d74d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4172a1b303748c985990a5174755159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b28e8be732764f72a43325e851408844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd956abb78464bb893586b8b1b8cdbfc",
            "placeholder": "​",
            "style": "IPY_MODEL_c07d8599323f4d45b374ce40c7eb2471",
            "value": "Connecting..."
          }
        },
        "bd956abb78464bb893586b8b1b8cdbfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c07d8599323f4d45b374ce40c7eb2471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83f52b6dfae24c218359dc486e30d3b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b89313146a96447f96a80a8a05ac8725",
            "placeholder": "​",
            "style": "IPY_MODEL_0edd507d1b2e4086a33a03ba549c6cc1",
            "value": "Kaggle credentials successfully validated."
          }
        },
        "b89313146a96447f96a80a8a05ac8725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0edd507d1b2e4086a33a03ba549c6cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rakza31/Code-Militants/blob/main/RSNA_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "Xritay63YRGe",
        "outputId": "f0bfae3f-3329-432f-e2a0-f737a7c82dc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "ba6e00aebe65498997d97a206acaf0a9",
            "b805d3f222374d2db10d97f2cd50ec95",
            "b0a0e5329299463f8221bc0346d2de41",
            "a734cea2dd2742c3946e5c5723c5121d",
            "c295fa9a5fe241ce93e88c7b29b9dd4f",
            "50418299f32b4803a7ff5a34e73f1bf7",
            "3a93ef68b76d47ffa8af108909cf24db",
            "09c470fa6dd24c1b8b5031e86853e05f",
            "c5acca357cc14060b6e4b2fb0a5545ec",
            "458af312174949a5b0981db395fc424b",
            "8b579461d248418c8028113f54522cdc",
            "16552956cc3e44dd864a111c55136f57",
            "3371c4865e5241cea66d5f0a7bb56951",
            "b73e41c87fb64aa9b1bc3d8bd0dd1893",
            "d757aa3788b5443d863eb9fca2bfdb1f",
            "f6b7e592da484e27bf02d11f50f6d74d",
            "e4172a1b303748c985990a5174755159",
            "b28e8be732764f72a43325e851408844",
            "bd956abb78464bb893586b8b1b8cdbfc",
            "c07d8599323f4d45b374ce40c7eb2471",
            "83f52b6dfae24c218359dc486e30d3b1",
            "b89313146a96447f96a80a8a05ac8725",
            "0edd507d1b2e4086a33a03ba549c6cc1"
          ]
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba6e00aebe65498997d97a206acaf0a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle credentials set.\n",
            "Kaggle credentials successfully validated.\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "rsna_breast_cancer_detection_path = kagglehub.competition_download('rsna-breast-cancer-detection')\n",
        "theoviel_rsna_breast_cancer_512_pngs_path = kagglehub.dataset_download('theoviel/rsna-breast-cancer-512-pngs')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "-mfYmiEdYRGf",
        "outputId": "87275093-1e04-4758-f82d-6e75c2b20973",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/competitions/data/download-all/rsna-breast-cancer-detection...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 2.21G/270G [01:19<2:40:38, 29.8MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2298600686.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# NOTEBOOK.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mrsna_breast_cancer_detection_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkagglehub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompetition_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rsna-breast-cancer-detection'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtheoviel_rsna_breast_cancer_512_pngs_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkagglehub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'theoviel/rsna-breast-cancer-512-pngs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/kagglehub/competition.py\u001b[0m in \u001b[0;36mcompetition_download\u001b[0;34m(handle, path, force_download)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_competition_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading competition: {h.to_url()} ...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mEXTRA_CONSOLE_BLOCK\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompetition_resolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/kagglehub/registry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimpl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/kagglehub/resolver.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, handle, path, force_download)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mSome\u001b[0m \u001b[0mcases\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mmight\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCompetition\u001b[0m \u001b[0mdatasource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAPI\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbased\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \"\"\"\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Note handles are immutable, so _resolve() could not have altered our reference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/kagglehub/http_resolver.py\u001b[0m in \u001b[0;36m_resolve\u001b[0;34m(self, h, path, force_download)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mdownload_needed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchive_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/kagglehub/clients.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(self, path, out_file, resource_handle, cached_path, extract_auto_compressed_file)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading from {url}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0m_download_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhash_object\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/kagglehub/clients.py\u001b[0m in \u001b[0;36m_download_file\u001b[0;34m(response, out_file, size_read, total_size, hash_object)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhash_object\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                         \u001b[0mhash_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "ra1xJGtbYRGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path to the CSV file\n",
        "rsna_path = '/kaggle/input/rsna-breast-cancer-detection/train.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df_rsna = pd.read_csv(rsna_path)\n",
        "\n",
        "df_rsna.head()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "ETP5ebb0YRGh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Display basic info\n",
        "df_rsna.info()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Hag3fAvmYRGh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Missing Values Analysis\n"
      ],
      "metadata": {
        "id": "GsjtuUjRYRGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking missing values in each column\n",
        "missing_values = df_rsna.isnull().sum()\n",
        "print(\"Missing Values in each column:\\n\", missing_values)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "baLRb8gbYRGi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics for both numerical and categorical columns\n",
        "summary_statistics = df_rsna.describe(include='all')\n",
        "print(\"Summary Statistics:\\n\", summary_statistics)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "UYf8M1EZYRGi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Set a high-quality style for the plot\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Plotting the distribution of 'age' with advanced styling\n",
        "plt.figure(figsize=(14, 8))\n",
        "n, bins, patches = plt.hist(df_rsna['age'].dropna(), bins=20, edgecolor='black', color='lightpink', alpha=1.0)\n",
        "\n",
        "# Title and labels\n",
        "plt.title('Age Distribution in Dataset', fontsize=20, fontweight='bold', color='midnightblue', pad=20)\n",
        "plt.xlabel('Age', fontsize=16, labelpad=10)\n",
        "plt.ylabel('Frequency', fontsize=16, labelpad=10)\n",
        "\n",
        "# Apply a pastel color gradient to the bars\n",
        "bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
        "colormap = plt.cm.Pastel1  # Choose a pastel color map\n",
        "for count, patch in zip(n, patches):\n",
        "    plt.setp(patch, 'facecolor', colormap((count - np.min(n)) / np.ptp(n)))\n",
        "\n",
        "# Adding a grid and text annotations for visual appeal\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "\n",
        "# Add annotations on top of each bar\n",
        "for count, x in zip(n, bin_centers):\n",
        "    plt.text(x, count + 2, f'{int(count)}', ha='center', va='bottom', fontsize=10, color='dimgray')\n",
        "\n",
        "# Customizing tick parameters\n",
        "plt.xticks(fontsize=12, color='slategray')\n",
        "plt.yticks(fontsize=12, color='slategray')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "i68vtqCHYRGi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set a high-quality style with pastel tones\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Plotting the distribution of 'density' with enhancements\n",
        "plt.figure(figsize=(12, 8))\n",
        "density_counts = df_rsna['density'].value_counts()\n",
        "bars = density_counts.plot(kind='bar', edgecolor='black', color='coral', alpha=1.0)\n",
        "\n",
        "# Title and labels\n",
        "plt.title('Distribution of Density in Dataset', fontsize=20, fontweight='bold', color='midnightblue', pad=20)\n",
        "plt.xlabel('Density', fontsize=16, labelpad=10)\n",
        "plt.ylabel('Frequency', fontsize=16, labelpad=10)\n",
        "\n",
        "# Add pastel colors to the bars\n",
        "colormap = plt.cm.Pastel2  # Pastel colormap\n",
        "for i, bar in enumerate(bars.containers[0]):  # Apply color gradient\n",
        "    bar.set_color(colormap(i / len(density_counts)))\n",
        "\n",
        "# Adding grid lines for better readability\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "\n",
        "# Adding annotations on top of each bar\n",
        "for i, (density, count) in enumerate(density_counts.items()):\n",
        "    plt.text(i, count + 20, f'{count}', ha='center', va='bottom', fontsize=12, color='dimgray')\n",
        "\n",
        "# Customizing tick parameters\n",
        "plt.xticks(fontsize=14, color='slategray')\n",
        "plt.yticks(fontsize=14, color='slategray')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "vy4OkJXiYRGi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Take Away from dataset Exploration:\n",
        "1. **Missing Values Analysis:** Remove rows where density is missing\n",
        "2. **Remove Implants:** Filter out rows where implants == 1\n",
        "3. **Dataset Imbalance:** A and D have least amount of images\n",
        "4. **Dataset Split:** Split dataset into train, val, test\n",
        "5. **Label Encoding:** Encode categorical labels into numeric e.g. A=0, B=1, C=2, D=3\n",
        "6. **Data Augmentation and Batch Generation:** Handling image data and feed it into deep learning model"
      ],
      "metadata": {
        "id": "s17DR0HtYRGj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing\n"
      ],
      "metadata": {
        "id": "BlsrWw-MYRGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the total number of rows before removing missing density values\n",
        "total_rows_before = len(df_rsna)\n",
        "print(\"Total rows before removing missing density values:\", total_rows_before)\n",
        "\n",
        "# Step 1: Drop rows with missing target variable (density)\n",
        "df_rsna_preprocessed = df_rsna.dropna(subset=['density'])\n",
        "\n",
        "# Count the total number of rows after removing missing density values\n",
        "total_rows_after = len(df_rsna_preprocessed)\n",
        "print(\"Total rows after removing missing density values:\", total_rows_after)\n",
        "\n",
        "# Display the first few rows of the DataFrame after removal\n",
        "df_rsna_preprocessed.head()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "Pkc3uW8eYRGj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the total number of rows before removal\n",
        "total_rows_before = len(df_rsna_preprocessed)\n",
        "print(\"Total rows before removing implants:\", total_rows_before)\n",
        "\n",
        "# Count the number of rows with implants\n",
        "implant_count = df_rsna_preprocessed[df_rsna_preprocessed['implant'] == 1].shape[0]\n",
        "print(\"Number of rows with implants (implant == 1):\", implant_count)\n",
        "\n",
        "# Remove rows with implants\n",
        "df_rsna_preprocessed = df_rsna_preprocessed[df_rsna_preprocessed['implant'] == 0]\n",
        "\n",
        "# Count the total number of rows after removal\n",
        "total_rows_after = len(df_rsna_preprocessed)\n",
        "print(\"Total rows after removing implants:\", total_rows_after)\n",
        "\n",
        "# Display the first few rows to confirm changes\n",
        "df_rsna_preprocessed.head()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "b9-nCbnnYRGj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Step 3: Encode Density (if density is categorical)\n",
        "# Assuming density categories are \"A\", \"B\", \"C\", etc.\n",
        "label_encoder = LabelEncoder()\n",
        "df_rsna_preprocessed['density_encoded'] = label_encoder.fit_transform(df_rsna_preprocessed['density'])\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "bIlFkUTwYRGj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_rsna_preprocessed.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "t39AJpSXYRGk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving df_rsna_preprocessed to a CSV file\n",
        "output_path = '/kaggle/working/df_rsna_preprocessed.csv'\n",
        "df_rsna_preprocessed.to_csv(output_path, index=False)\n",
        "print(\"File saved to:\", output_path)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "gCPZ1gUsYRGk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Specify the patient ID to display\n",
        "patient_id_to_display = 10095\n",
        "\n",
        "# Filter for the specific patient and required views\n",
        "patient_data = df_rsna_preprocessed[(df_rsna_preprocessed['patient_id'] == patient_id_to_display) &\n",
        "                                    (((df_rsna_preprocessed['laterality'] == 'R') & (df_rsna_preprocessed['view'] == 'CC')) |\n",
        "                                     ((df_rsna_preprocessed['laterality'] == 'L') & (df_rsna_preprocessed['view'] == 'CC')) |\n",
        "                                     ((df_rsna_preprocessed['laterality'] == 'R') & (df_rsna_preprocessed['view'] == 'MLO')) |\n",
        "                                     ((df_rsna_preprocessed['laterality'] == 'L') & (df_rsna_preprocessed['view'] == 'MLO')))]\n",
        "\n",
        "# Select the first image for each unique combination of `laterality` and `view`\n",
        "patient_data_unique_views = patient_data.drop_duplicates(subset=['laterality', 'view'])\n",
        "\n",
        "# Check if we have exactly 4 images (one for each combination of view and laterality)\n",
        "if len(patient_data_unique_views) == 4:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "    fig.suptitle(f\"Images for Patient ID: {patient_id_to_display}\", fontsize=16)\n",
        "\n",
        "    for i, (idx, row) in enumerate(patient_data_unique_views.iterrows()):\n",
        "        # Load image based on image_id\n",
        "        image_path = f\"/kaggle/input/rsna-breast-cancer-512-pngs/{row['patient_id']}_{row['image_id']}.png\"  # Update path and extension as needed\n",
        "        img = mpimg.imread(image_path)\n",
        "\n",
        "        # Position in 2x2 grid\n",
        "        ax = axes[i // 2, i % 2]\n",
        "\n",
        "        # Display image and metadata\n",
        "        ax.imshow(img, cmap='gray')\n",
        "        ax.axis('off')\n",
        "        ax.set_title(f\"Image ID: {row['image_id']}\\n\"\n",
        "                     f\"Laterality: {row['laterality']}\\n\"\n",
        "                     f\"View: {row['view']}\\n\"\n",
        "                     f\"Density: {row['density']}\", fontsize=12)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to fit title\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Could not find exactly 4 unique images (one per view) for this patient.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "hqM33KWrYRGk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Splitting"
      ],
      "metadata": {
        "id": "kOUifAcbYRGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set a high-quality style with pastel tones\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Plotting the distribution of 'density' categories with enhancements\n",
        "plt.figure(figsize=(10, 7))\n",
        "density_counts = df_rsna_preprocessed['density'].value_counts()\n",
        "bars = density_counts.plot(kind='bar', color='lightsteelblue', edgecolor='black', alpha=0.85)\n",
        "\n",
        "# Title and labels\n",
        "plt.title('Distribution of Density Categories', fontsize=20, fontweight='bold', color='navy', pad=20)\n",
        "plt.xlabel('Density Category', fontsize=16, labelpad=10)\n",
        "plt.ylabel('Frequency', fontsize=16, labelpad=10)\n",
        "\n",
        "# Adding a pastel color gradient to the bars\n",
        "colormap = plt.cm.Pastel2\n",
        "for i, bar in enumerate(bars.containers[0]):\n",
        "    bar.set_color(colormap(i / len(density_counts)))\n",
        "\n",
        "# Adding a dashed grid for readability\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "\n",
        "# Adding annotations on top of each bar for counts\n",
        "for i, (density, count) in enumerate(density_counts.items()):\n",
        "    plt.text(i, count + 5, f'{count}', ha='center', va='bottom', fontsize=12, color='navy')\n",
        "\n",
        "# Customizing ticks\n",
        "plt.xticks(fontsize=14, color='slategray', rotation=0)\n",
        "plt.yticks\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "H9PCsK75YRGk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the count of images in each 'density' category\n",
        "image_count_per_density = df_rsna_preprocessed['density'].value_counts()\n",
        "\n",
        "# Print the count of images per density category\n",
        "print(\"Count of images in each density category:\")\n",
        "print(image_count_per_density)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "XnplPNbRYRGk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset (if not already loaded)\n",
        "df = df_rsna_preprocessed  # Assuming df_rsna_preprocessed is your main DataFrame\n",
        "\n",
        "# Step 1: Group by patient_id and sample to ensure unique patients in each set\n",
        "# We'll use `density` for stratification since that’s our target\n",
        "\n",
        "# Extract unique patients with their associated densities (majority class per patient)\n",
        "patient_data = df.groupby('patient_id')['density'].agg(lambda x: x.mode()[0]).reset_index()\n",
        "\n",
        "# Step 2: Perform stratified sampling to split patients into train, val, and test\n",
        "\n",
        "# First, split into 80% training and 20% temp (which will later be split into val and test)\n",
        "train_patients, temp_patients = train_test_split(\n",
        "    patient_data, test_size=0.2, stratify=patient_data['density'], random_state=42\n",
        ")\n",
        "\n",
        "# Next, split the temp set into 50% validation and 50% test (which is 10% each of the original dataset)\n",
        "val_patients, test_patients = train_test_split(\n",
        "    temp_patients, test_size=0.5, stratify=temp_patients['density'], random_state=42\n",
        ")\n",
        "\n",
        "# Step 3: Map the patient splits back to the main DataFrame\n",
        "\n",
        "# Filter the main DataFrame for each set\n",
        "train_df = df[df['patient_id'].isin(train_patients['patient_id'])]\n",
        "val_df = df[df['patient_id'].isin(val_patients['patient_id'])]\n",
        "test_df = df[df['patient_id'].isin(test_patients['patient_id'])]\n",
        "\n",
        "# Display the sizes of each split\n",
        "print(\"Training set size:\", len(train_df))\n",
        "print(\"Validation set size:\", len(val_df))\n",
        "print(\"Test set size:\", len(test_df))\n",
        "\n",
        "# Optionally, save these sets to CSVs\n",
        "train_df.to_csv('/kaggle/working/train_df.csv', index=False)\n",
        "val_df.to_csv('/kaggle/working/val_df.csv', index=False)\n",
        "test_df.to_csv('/kaggle/working/test_df.csv', index=False)\n",
        "\n",
        "print(\"Datasets saved successfully.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "m68mLCB8YRGk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Category-wise image counts in each set\n",
        "train_category_counts = train_df['density'].value_counts()\n",
        "val_category_counts = val_df['density'].value_counts()\n",
        "test_category_counts = test_df['density'].value_counts()\n",
        "\n",
        "# Display category-wise counts\n",
        "print(\"Category-wise image counts in each set:\")\n",
        "print(\"Training set:\\n\", train_category_counts)\n",
        "print(\"\\nValidation set:\\n\", val_category_counts)\n",
        "print(\"\\nTest set:\\n\", test_category_counts)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "CNkWPG6jYRGl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "\n",
        "class BreastDensityDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the CSV file with annotations.\n",
        "            img_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied on an image.\n",
        "        \"\"\"\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get patient_id, image_id, and density label\n",
        "        patient_id = self.data.iloc[idx]['patient_id']\n",
        "        image_id = self.data.iloc[idx]['image_id']\n",
        "        label = self.data.iloc[idx]['density_encoded']  # Using the existing encoded label directly\n",
        "\n",
        "        # Construct the file path with {patient_id}_{image_id}.png\n",
        "        img_path = os.path.join(self.img_dir, f\"{patient_id}_{image_id}.png\")\n",
        "\n",
        "        # Load the image\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB format\n",
        "\n",
        "        # Apply transformations if specified\n",
        "        if self.transform:\n",
        "            # Apply Albumentations transform, which requires a dictionary\n",
        "            image = self.transform(image=image)[\"image\"]\n",
        "\n",
        "        return image, label, patient_id, image_id"
      ],
      "metadata": {
        "trusted": true,
        "id": "l_nk_LXkYRGl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory containing images\n",
        "img_dir = \"/kaggle/input/rsna-breast-cancer-512-pngs\"  # Update this path to your image folder\n",
        "\n",
        "# Paths to CSV files for each dataset split\n",
        "train_csv = '/kaggle/working/train_df.csv'\n",
        "val_csv = '/kaggle/working/val_df.csv'\n",
        "test_csv = '/kaggle/working/test_df.csv'"
      ],
      "metadata": {
        "trusted": true,
        "id": "k7g8kT3tYRGl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for duplicates in each of the train, validation, and test sets based on 'patient_id' and 'image_id' combination\n",
        "\n",
        "train_duplicates = train_df.duplicated(subset=['patient_id', 'image_id']).sum()\n",
        "val_duplicates = val_df.duplicated(subset=['patient_id', 'image_id']).sum()\n",
        "test_duplicates = test_df.duplicated(subset=['patient_id', 'image_id']).sum()\n",
        "\n",
        "# Displaying the results\n",
        "print(\"Number of duplicates in Training set:\", train_duplicates)\n",
        "print(\"Number of duplicates in Validation set:\", val_duplicates)\n",
        "print(\"Number of duplicates in Test set:\", test_duplicates)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "_TBaAmoaYRGl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "\n",
        "# Albumentations transformations for training\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(224, 224),  # Resize to 299x299 for InceptionV3\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.5),\n",
        "    A.MedianBlur(blur_limit=5, p=0.1),\n",
        "    A.GaussianBlur(blur_limit=(3, 7), p=0.1),\n",
        "    A.GaussNoise(p=0.2),\n",
        "    A.ElasticTransform(p=0.1),\n",
        "    A.GridDistortion(p=0.1),\n",
        "    A.OpticalDistortion(p=0.1),\n",
        "    A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.5),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# Albumentations transformations for validation and test (without augmentation)\n",
        "val_test_transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# Create dataset instances\n",
        "train_dataset = BreastDensityDataset(csv_file=train_csv, img_dir=img_dir, transform=train_transform)\n",
        "val_dataset = BreastDensityDataset(csv_file=val_csv, img_dir=img_dir, transform=val_test_transform)\n",
        "test_dataset = BreastDensityDataset(csv_file=test_csv, img_dir=img_dir, transform=val_test_transform)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "xK75VqIkYRGl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to display a few images from the dataset with {patient_id}_{image_id} and density\n",
        "def display_sample_images(dataset, num_images=4):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    for i in range(num_images):\n",
        "        # Get a sample from the dataset\n",
        "        image, label, patient_id, image_id = dataset[i]\n",
        "\n",
        "        # Convert to grayscale by taking only one channel, e.g., the first channel\n",
        "        image = image[0]  # Assuming the image is (3, H, W), take the first channel\n",
        "\n",
        "        # Plot the image in grayscale\n",
        "        ax = plt.subplot(1, num_images, i + 1)\n",
        "        plt.imshow(image, cmap='gray')  # Use 'gray' colormap for grayscale display\n",
        "        plt.axis(\"off\")\n",
        "        ax.set_title(f\"{patient_id}_{image_id}\\nDensity: {label}\")  # Adding density label\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display sample images from test_dataset\n",
        "display_sample_images(test_dataset, num_images=4)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "9vJ2m0l5YRGl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DeiT (Data-efficient Image Transformers) - 2020**\n"
      ],
      "metadata": {
        "id": "5Jp8NOC9YRGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchsummary\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "0uhJpvthYRGl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import timm\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "\n",
        "# Initialize the model\n",
        "model = timm.create_model('deit_base_patch16_224', pretrained=True)\n",
        "\n",
        "# Adjust the final layer for your specific number of classes\n",
        "num_classes = 4  # Modify as needed for your dataset\n",
        "in_features = model.get_classifier().in_features\n",
        "model.head = nn.Linear(in_features, num_classes)\n",
        "\n",
        "# Move model to GPU if available and wrap with DataParallel for multiple GPUs\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
        "    model = nn.DataParallel(model)  # This will parallelize across multiple GPUs\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "# Calculate total and trainable parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "# Print model architecture and parameter details\n",
        "#print(f\"Model Architecture:\\n{model}\")\n",
        "print(f\"\\nTotal Parameters: {total_params:,}\")\n",
        "print(f\"Trainable Parameters: {trainable_params:,}\")\n",
        "\n",
        "# Calculate model size in MB\n",
        "param_size = 4  # Size of each parameter in bytes (float32 takes 4 bytes)\n",
        "model_size_mb = total_params * param_size / (1024 ** 2)\n",
        "print(f\"Model Size: {model_size_mb:.2f} MB\")\n",
        "\n",
        "# Print a detailed summary of the model layers (optional, may be long)\n",
        "#print(\"\\nDetailed Model Summary:\")\n",
        "#summary(model, (3, 224, 224))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZJ_VGfLMYRGm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training Loop**"
      ],
      "metadata": {
        "id": "v0RbhUO8YRGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import timm\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 32\n",
        "learning_rate = 1e-4\n",
        "epochs = 50  # Increased to allow early stopping\n",
        "patience = 10  # Early stopping patience\n",
        "\n",
        "# Define data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "# Define optimizer and adaptive learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training tracking variables\n",
        "best_val_accuracy = 0.0\n",
        "best_model_weights = None\n",
        "train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n",
        "no_improve_epochs = 0  # Track epochs without improvement for early stopping\n",
        "\n",
        "# Track total training time\n",
        "start_time = time.time()\n",
        "\n",
        "# Training and validation loops\n",
        "for epoch in range(epochs):\n",
        "    epoch_start_time = time.time()\n",
        "\n",
        "    # Training loop with progress bar\n",
        "    model.train()\n",
        "    total_train_loss = 0.0\n",
        "    correct_train = 0\n",
        "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\", leave=False)\n",
        "    for images, labels, _, _ in train_bar:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct_train += (preds == labels).sum().item()  # Calculate train accuracy\n",
        "        train_bar.set_postfix({\"Batch Loss\": loss.item()})\n",
        "\n",
        "    # Calculate training loss and accuracy\n",
        "    train_loss = total_train_loss / len(train_loader)\n",
        "    train_accuracy = correct_train / len(train_loader.dataset)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Validation loop with progress bar\n",
        "    model.eval()\n",
        "    total_val_loss = 0.0\n",
        "    correct_val = 0\n",
        "    val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} - Validation\", leave=False)\n",
        "    with torch.no_grad():\n",
        "        for images, labels, _, _ in val_bar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct_val += (preds == labels).sum().item()\n",
        "            val_bar.set_postfix({\"Batch Loss\": loss.item()})\n",
        "\n",
        "    # Calculate validation loss and accuracy\n",
        "    val_loss = total_val_loss / len(val_loader)\n",
        "    val_accuracy = correct_val / len(val_loader.dataset)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    # Adaptive learning rate scheduler step\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Print statistics for the epoch\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Check if current model is the best\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        best_model_weights = model.state_dict()  # Save best model weights\n",
        "        no_improve_epochs = 0  # Reset early stopping counter\n",
        "        print(\"Best model updated.\")\n",
        "    else:\n",
        "        no_improve_epochs += 1  # Increase early stopping counter\n",
        "\n",
        "    # Early stopping check\n",
        "    if no_improve_epochs >= patience:\n",
        "        print(\"Early stopping triggered.\")\n",
        "        break\n",
        "\n",
        "    # Track time per epoch\n",
        "    epoch_time = time.time() - epoch_start_time\n",
        "    print(f\"Epoch {epoch+1} completed in {epoch_time:.2f} seconds.\")\n",
        "\n",
        "# Calculate total training time\n",
        "total_time = time.time() - start_time\n",
        "print(f\"\\nTotal Training Time: {total_time // 60:.0f} minutes, {total_time % 60:.2f} seconds.\")\n",
        "\n",
        "# Load best model weights\n",
        "model.load_state_dict(best_model_weights)\n",
        "\n",
        "# Save best model weights\n",
        "torch.save(best_model_weights, 'best_deit_model.pth')\n",
        "print(\"Best model weights saved to 'best_deit_model.pth'.\")\n",
        "\n",
        "# Plot training and validation curves\n",
        "epochs_range = range(1, len(train_losses) + 1)\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, train_losses, label='Train Loss')\n",
        "plt.plot(epochs_range, val_losses, label='Val Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, train_accuracies, label='Train Accuracy')\n",
        "plt.plot(epochs_range, val_accuracies, label='Val Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "wGVsbuM0YRGm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "model.eval()\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels, _, _ in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "\n",
        "test_accuracy = correct / len(test_loader.dataset)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "DxFLq6ZmYRGm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# After training, evaluate on the test or validation set\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels, _, _ in val_loader:  # Use validation or test loader\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Generate Classification Report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=[f\"Class {i}\" for i in range(num_classes)]))\n",
        "\n",
        "# Compute Sensitivity (Recall) for Each Class\n",
        "# Sensitivity is already included in the classification report as recall.\n",
        "\n",
        "# Generate and Plot Confusion Matrix\n",
        "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=[f\"Class {i}\" for i in range(num_classes)])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "KeaIKPOXYRGm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have the necessary imports\n",
        "import random\n",
        "import torch.nn.functional as F  # For softmax function\n",
        "\n",
        "def display_predictions_random_patients(dataset, model, num_images=4, num_patients=2):\n",
        "    model.eval()\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    # Get unique patient IDs from the dataset\n",
        "    unique_patients = list(set([dataset[i][2] for i in range(len(dataset))]))  # Assuming patient_id is the 3rd item in the tuple\n",
        "    selected_patients = random.sample(unique_patients, num_patients)  # Randomly select patient IDs\n",
        "\n",
        "    # Initialize image index\n",
        "    img_count = 0\n",
        "\n",
        "    for patient_id in selected_patients:\n",
        "        # Get images for the selected patient\n",
        "        patient_images = [i for i in range(len(dataset)) if dataset[i][2] == patient_id]\n",
        "\n",
        "        for idx in patient_images:\n",
        "            if img_count >= num_images:\n",
        "                break  # Stop if we have reached the desired number of images\n",
        "\n",
        "            # Get image and label from dataset\n",
        "            image, label, _, image_id = dataset[idx]\n",
        "\n",
        "            # Move image to GPU and add batch dimension\n",
        "            with torch.no_grad():\n",
        "                image = image.unsqueeze(0).to(device)\n",
        "                output = model(image)\n",
        "\n",
        "                # Calculate confidence score\n",
        "                probabilities = F.softmax(output, dim=1)  # Apply softmax to get probabilities\n",
        "                confidence, pred = torch.max(probabilities, 1)  # Get predicted class and its confidence score\n",
        "\n",
        "            # Rearrange image dimensions for Matplotlib\n",
        "            image = image.squeeze().cpu().numpy()  # Remove batch dimension and convert to numpy array\n",
        "            if image.ndim == 2:  # If the image is already in HxW format\n",
        "                image_to_show = image\n",
        "            elif image.shape[0] == 3:  # If the image is in CxHxW format\n",
        "                image_to_show = image.transpose(1, 2, 0)  # Convert to HxWxC\n",
        "                # Convert to grayscale if needed\n",
        "                if image_to_show.shape[2] == 3:\n",
        "                    image_to_show = image_to_show.mean(axis=2)  # Convert RGB to grayscale\n",
        "\n",
        "            # Plotting\n",
        "            ax = plt.subplot(1, num_images, img_count + 1)\n",
        "            plt.imshow(image_to_show, cmap='gray')  # Force grayscale\n",
        "            plt.title(f\"Pred: {pred.item()} (Conf: {confidence.item() * 100:.2f}%)\\nTrue: {label}\")\n",
        "            plt.axis(\"off\")\n",
        "\n",
        "            img_count += 1\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Call function to display predictions for 2 random patients\n",
        "display_predictions_random_patients(test_dataset, model, num_images=4, num_patients=2)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "ro4YZ_oMYRGm"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}